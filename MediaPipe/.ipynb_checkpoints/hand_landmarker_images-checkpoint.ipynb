{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_cQX8dWu4Dv"
   },
   "source": [
    "# Hand Landmarks Detection with Image MediaPipe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OMjuVQiDYJKF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Complete\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n",
    "response = requests.get(url)\n",
    "with open(\"hand_landmarker.task\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "print(\"Download Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Fingers with six points\n",
    "\n",
    "Range for each finger:\n",
    "\n",
    "* 0: Wrist\n",
    "* 1-4: Thumb \n",
    "* 5-8: Index \n",
    "* 9-12: Middle \n",
    "* 13-16: Ring \n",
    "* 17-20: Pinky "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "# The six points of the two fingers\n",
    "fingers_indices = [4, 8, 1, 0, 5, 6]\n",
    "\n",
    "# The environmnet path\n",
    "environment_path = \"C:\\\\MARTIN EDUARDO\\\\University Of Leeds\\\\Dissertation\\\\Classification_bradykinesia_KalmanFilter\"\n",
    "\n",
    "# The name of the Final csv File with all landmarks\n",
    "csv_file = environment_path + \"\\\\\" +'mediaPipe_images.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54)\n",
    "\n",
    "# draw the landmarks on the image\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    handedness_list = detection_result.handedness\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "    \n",
    "    # Loop through the detected hands to visualize.\n",
    "    for idx in range(len(hand_landmarks_list)):\n",
    "        hand_landmarks = hand_landmarks_list[idx]\n",
    "        handedness = handedness_list[idx]\n",
    "\n",
    "        # draw the hand landmarks\n",
    "        hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        hand_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "        ])\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks_proto,\n",
    "          solutions.hands.HAND_CONNECTIONS,\n",
    "          solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "          solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        # get the top left corner of the detected hand's bounding box.\n",
    "        height, width, _ = annotated_image.shape\n",
    "        x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "        y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "        text_x = int(min(x_coordinates) * width)\n",
    "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "        # Draw handedness (left or right hand) on the image.\n",
    "        cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    return annotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for process the image using the original image, the coordenates of the fingers and save the drawn image\n",
    "def process_image(file_path, image_name, detector, fingers_indices, image_output_name, output_dir):\n",
    "    # Load the input image\n",
    "    if os.path.isfile(file_path):\n",
    "        image = mp.Image.create_from_file(file_path)\n",
    "\n",
    "        # detect hand landmarks from the input image\n",
    "        detection_result = detector.detect(image)\n",
    "\n",
    "        # verify that there is at least one hand detected\n",
    "        if detection_result.hand_landmarks:\n",
    "            row = [image_name]  # Include the file name/path as the first element\n",
    "\n",
    "            # iterate over landmark indices\n",
    "            for idx in fingers_indices:\n",
    "                landmark = detection_result.hand_landmarks[0][idx]\n",
    "                row.extend([landmark.x, landmark.y])\n",
    "                \n",
    "            # process and visualize the result\n",
    "            annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_image_path = os.path.join(output_dir, image_output_name)\n",
    "            cv2.imwrite(output_image_path, cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            return row, detection_result, image\n",
    "        else:\n",
    "            return None, None, None\n",
    "    else:\n",
    "            return None, None, None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Create an HandLandmarker object\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 2: Load the path of the images\n",
    "student_path =  environment_path +\"\\\\Data\\\\images_data\\\\\"\n",
    "\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Name of columns\n",
    "    field = [\"image_name\"] + [\"finger_x\", \"finger_y\", \"thumb_x\", \"thumb_y\", \"wristlow_x\", \"wristlow_y\",\n",
    "                              \"wristhigh_x\", \"wristhigh_y\", \"knuckle1_x\", \"knuckle1_y\", \"knuckle2_x\", \"knuckle2_y\"]\n",
    "    writer.writerow(field)\n",
    "    # Get the folder names (students folders)\n",
    "    student_names = [name for name in os.listdir(student_path) if os.path.isdir(os.path.join(student_path, name))]\n",
    "    \n",
    "     #  Loop for Student\n",
    "    for student_name in student_names:\n",
    "        folder_path = student_path + \"\\\\\" + student_name\n",
    "        # Get the folder names (videos folders)\n",
    "        folder_names = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "\n",
    "        #  Loop for Folder\n",
    "        for folder_name in folder_names:\n",
    "            image_path = folder_path + \"\\\\\" + folder_name \n",
    "            images_count = len([name for name in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, name))]) - 2 \n",
    "            \n",
    "            # folder for image labeled\n",
    "            output_dir = folder_path + \"\\\\\" + folder_name + \"_labelled\"\n",
    "            \n",
    "            # Loop for Image\n",
    "            for image_num in range(0,images_count):\n",
    "                if image_num < 10:\n",
    "                    img_pref = \"img00\" \n",
    "                elif image_num < 100:\n",
    "                    img_pref = \"img0\"\n",
    "                else:\n",
    "                    img_pref = \"img\"\n",
    "                image_output_name = folder_name + \"_\" + img_pref + str(image_num) + \".png\"\n",
    "                image_file = image_path + \"\\\\\" + img_pref + str(image_num) + \".png\"\n",
    "                image_name = folder_name + \"\\\\\" +img_pref + str(image_num) + \".png\"\n",
    "                \n",
    "                # STEP 3: Detect hand landmarks from the input image and Process the classification result.\n",
    "                result_row, detection_result, image = process_image(image_file, image_name ,detector, fingers_indices,\n",
    "                                                                    image_output_name, output_dir)\n",
    "                if result_row:\n",
    "                    # STEP 4: Save the hand landmarks in the csv\n",
    "                    writer.writerow(result_row)\n",
    "        print(f\"Finish with Student folder : {student_name}\")\n",
    "\n",
    "                    #Mostrar la imagen procesada con los landmarks dibujados\n",
    "                    #annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "                    #annotated_image_bgr = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "                    #plt.imshow(cv2.cvtColor(annotated_image_bgr, cv2.COLOR_BGR2RGB))\n",
    "                    #plt.axis('off')  # Hide the axes\n",
    "                    #plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "h2q27gKz1H20"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
