{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_cQX8dWu4Dv"
   },
   "source": [
    "# Hand Landmarks Detection with Video MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OMjuVQiDYJKF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Complete\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n",
    "response = requests.get(url)\n",
    "with open(\"hand_landmarker.task\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "print(\"Download Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Fingers with six points\n",
    "\n",
    "Range for each finger:\n",
    "\n",
    "* 0: Wrist\n",
    "* 1-4: Thumb \n",
    "* 5-8: Index \n",
    "* 9-12: Middle \n",
    "* 13-16: Ring \n",
    "* 17-20: Pinky "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# The six points of the two fingers\n",
    "fingers_indices = [4, 8, 1, 0, 5, 6]\n",
    "\n",
    "# The environmnet path\n",
    "environment_path = \"C:\\\\MARTIN EDUARDO\\\\University Of Leeds\\\\Dissertation\\\\Classification_bradykinesia_KalmanFilter\"\n",
    "\n",
    "# The name of the Final csv File with all landmarks\n",
    "csv_file = environment_path + \"\\\\\" +'mediaPipe_videos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54)  # vibrant green\n",
    "\n",
    "# function to draw landmarks on image\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    handedness_list = detection_result.handedness\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    for idx in range(len(hand_landmarks_list)):\n",
    "        hand_landmarks = hand_landmarks_list[idx]\n",
    "        handedness = handedness_list[idx]\n",
    "\n",
    "        hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        hand_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "        ])\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks_proto,\n",
    "            mp.solutions.hands.HAND_CONNECTIONS,\n",
    "            mp.solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp.solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        height, width, _ = annotated_image.shape\n",
    "        x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "        y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "        text_x = int(min(x_coordinates) * width)\n",
    "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "        cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    return annotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin Espinoza\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with Video  : OC04_R_10s\n",
      "Finish with Video  : OC13_R_10s\n",
      "Finish with Video  : P01_R_10s\n",
      "Finish with Video  : P02_R_10s\n",
      "Finish with Video  : P04_R_10s\n",
      "Finish with Video  : P05_R_10s\n",
      "Finish with Video  : P56_R_10s\n",
      "Finish with Video  : YC03_R_10s\n",
      "Finish with Video  : YC105_R_10s\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# create hand landmarker instance in video mode\n",
    "options = HandLandmarkerOptions(base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.VIDEO, num_hands=2)\n",
    "\n",
    "# path of videos\n",
    "student_path =  environment_path +\"\\\\Data\\\\videos_data\\\\videos_lowfps\\\\\"\n",
    "\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    #columns name\n",
    "    field = [\"image_name\"] + [\"finger_x\", \"finger_y\", \"thumb_x\", \"thumb_y\", \"wristlow_x\", \"wristlow_y\",\n",
    "                              \"wristhigh_x\", \"wristhigh_y\", \"knuckle1_x\", \"knuckle1_y\", \"knuckle2_x\", \"knuckle2_y\"]\n",
    "    writer.writerow(field)\n",
    "    \n",
    "    # Get the folder names (students folders)\n",
    "    student_names = [name for name in os.listdir(student_path) if os.path.isdir(os.path.join(student_path, name))]\n",
    "    \n",
    "    #  students folders loop \n",
    "    for student_name in student_names:\n",
    "        video_path = student_path + student_name \n",
    "        video_names = [os.path.splitext(name)[0] for name in os.listdir(video_path) if os.path.isfile(os.path.join(video_path, name))]\n",
    "\n",
    "        # path where the new image is saved\n",
    "        output_dir = environment_path +\"\\\\Data\\\\videos_data\\\\videos_lowfps_labelled\\\\\"\n",
    "        \n",
    "        # videos loop\n",
    "        for video_name in video_names:\n",
    "            image_num = 0\n",
    "            # each video\n",
    "            cap = cv2.VideoCapture(video_path + \"\\\\\" + video_name + \".mp4\")\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            \n",
    "            output_video_path = os.path.join(output_dir, f\"{video_name}_labelled.mp4\")\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "            \n",
    "            with HandLandmarker.create_from_options(options) as landmarker:\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "\n",
    "                    # convert the frame to RGB format\n",
    "                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "\n",
    "                    # perform hand landmarks detection\n",
    "                    frame_timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "                    detection_result = landmarker.detect_for_video(mp_image, frame_timestamp_ms)\n",
    "\n",
    "                    # Annotate the frame with landmarks\n",
    "                    annotated_frame = draw_landmarks_on_image(rgb_frame, detection_result)\n",
    "\n",
    "                    # convert the annotated frame back to BGR for OpenCV display\n",
    "                    bgr_annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)\n",
    "                    #cv2.imshow('Hand Landmarks', bgr_annotated_frame)\n",
    "                    out.write(bgr_annotated_frame)\n",
    "\n",
    "                    if detection_result.hand_landmarks:\n",
    "                        if image_num < 10:\n",
    "                            img_pref = \"img00\" \n",
    "                        elif image_num < 100:\n",
    "                            img_pref = \"img0\"\n",
    "                        else:\n",
    "                            img_pref = \"img\"\n",
    "                        output_image = video_name + \"\\\\\" + img_pref + str(image_num) + \".png\"\n",
    "                        row = [output_image]\n",
    "                        # Iterate over landmark indices\n",
    "                        for idx in fingers_indices:\n",
    "                            landmark = detection_result.hand_landmarks[0][idx]\n",
    "                            row.extend([landmark.x, landmark.y])\n",
    "                        writer.writerow(row)\n",
    "                    image_num += 1\n",
    "                    \n",
    "            # Release resources\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(f\"Finish with Video  : {video_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "h2q27gKz1H20"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
