{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff39ff9d",
   "metadata": {},
   "source": [
    "# Parkinson Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the file\n",
    "environment_path = \"C:\\\\MARTIN EDUARDO\\\\University Of Leeds\\\\Dissertation\\\\Classification_bradykinesia_KalmanFilter\"\n",
    "file_path = environment_path + \"\\\\mediaPipe_videos.csv\"\n",
    "\n",
    "class ParkinsonRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(ParkinsonRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device) \n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "# read the file\n",
    "def read_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# read videos\n",
    "def read_videos(file_path):\n",
    "    #test_videos_path = environment_path + \"\\\\Data\\\\videos_data\\\\test_videos_60fps\\\\\"\n",
    "    student_names = [name for name in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, name))]\n",
    "    all_videos = []\n",
    "    for student_name in student_names:\n",
    "        video_path = os.path.join(file_path, student_name)\n",
    "        video_names = [os.path.splitext(name)[0] for name in os.listdir(video_path) if os.path.isfile(os.path.join(video_path, name))]\n",
    "        all_videos.extend(video_names)\n",
    "    return all_videos\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "def calculate_maxT(df, all_videos):\n",
    "    maxT = 0\n",
    "    for video in all_videos:\n",
    "        maxT = max(maxT, df[df['image_name'].str.startswith(video)].shape[0])\n",
    "    return maxT\n",
    "\n",
    "\n",
    "# fill the tensor and labels\n",
    "def fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT):\n",
    "    num_videos = len(all_videos)\n",
    "    for i, video in enumerate(all_videos):\n",
    "        video_data = df[df['image_name'].str.startswith(video)]\n",
    "        T = video_data.shape[0]\n",
    "        if T <= maxT:\n",
    "            mytensor[i, 0, :T] = video_data['finger_x']\n",
    "            mytensor[i, 1, :T] = video_data['finger_y']\n",
    "            mytensor[i, 2, :T] = video_data['thumb_x']\n",
    "            mytensor[i, 3, :T] = video_data['thumb_y']\n",
    "        else:\n",
    "            mytensor[i, 0, :maxT] = video_data['finger_x'][:maxT]\n",
    "            mytensor[i, 1, :maxT] = video_data['finger_y'][:maxT]\n",
    "            mytensor[i, 2, :maxT] = video_data['thumb_x'][:maxT]\n",
    "            mytensor[i, 3, :maxT] = video_data['thumb_y'][:maxT]\n",
    "        if video.startswith('P'):\n",
    "            labels[i] = 1\n",
    "    return mytensor, labels\n",
    "\n",
    "# dataloaders for training\n",
    "def create_train_and_validation_loaders(tensor_x, tensor_y, batch_size):\n",
    "    # split into training and validation\n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    validation_split = 0.2\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    validation_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "# train the Parkinson model\n",
    "def training_model(model, train_loader, validation_loader, labels, num_epochs, learning_rate):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # to store the losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, labels in train_loader:\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in validation_loader:\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(validation_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "    return model, train_losses, val_losses\n",
    "                              \n",
    "# make the predictions\n",
    "def make_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            outputs = model(sequences)\n",
    "            predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "            test_predictions.extend(predictions)\n",
    "            test_targets.extend(labels.numpy())\n",
    "\n",
    "    # metrics\n",
    "    test_predictions = np.array(test_predictions).flatten()\n",
    "    test_targets = np.array(test_targets)\n",
    "\n",
    "    accuracy = accuracy_score(test_targets, np.round(test_predictions))\n",
    "    recall = recall_score(test_targets, np.round(test_predictions))\n",
    "    f1 = f1_score(test_targets, np.round(test_predictions))\n",
    "    roc_auc = roc_auc_score(test_targets, test_predictions)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1-score: {f1:.4f}')\n",
    "    print(f'Test AUROC: {roc_auc:.4f}')\n",
    "    \n",
    "# ploting the losses\n",
    "def plot_losses(train_losses, val_losses, num_epochs):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# models parameters\n",
    "batch_size = 32\n",
    "input_size = 4\n",
    "hidden_size = 256  \n",
    "num_layers = 3\n",
    "output_size = 1\n",
    "learning_rate = 0.0001 \n",
    "dropout = 0.5 \n",
    "num_epochs = 200\n",
    "\n",
    "# read the files)\n",
    "df = pd.read_csv(file_path) # train file\n",
    "\n",
    "# read videos\n",
    "all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\videos_lowfps\\\\\")\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "maxT = calculate_maxT(df, all_videos)\n",
    "\n",
    "# create the tensor and labels\n",
    "num_videos = len(all_videos)\n",
    "mytensor = np.zeros([num_videos, 4, maxT])\n",
    "labels = np.zeros(num_videos)\n",
    "\n",
    "# fill the tensor and labels\n",
    "fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "tensor_x = torch.tensor(mytensor, dtype=torch.float32).permute(0, 2, 1) \n",
    "tensor_y = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# train and validation loaders\n",
    "train_loader, validation_loader = create_train_and_validation_loaders(tensor_x, tensor_y, batch_size)\n",
    "\n",
    "# train the model\n",
    "model = ParkinsonRNN(input_size, hidden_size, num_layers, output_size, dropout)\n",
    "model, train_losses, val_losses = training_model(model, train_loader, validation_loader, labels, num_epochs, learning_rate)\n",
    "\n",
    "plot_losses(train_losses, val_losses, num_epochs)\n",
    "\n",
    "# read the file (dataframe)\n",
    "test_df = read_file(environment_path + \"\\\\test_mediaPipe_videos.csv\")\n",
    "\n",
    "# read the videos (list)\n",
    "test_all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\test_videos_lowfps\\\\\")\n",
    "                              \n",
    "# calculate the number of max frames (T)\n",
    "test_maxT = calculate_maxT(test_df, test_all_videos)\n",
    "                              \n",
    "# create the tensor and labels\n",
    "test_num_videos = len(test_all_videos)\n",
    "test_mytensor = np.zeros([test_num_videos, 4, test_maxT])\n",
    "test_labels = np.zeros(test_num_videos)\n",
    "                      \n",
    "# fill the tensor and labels\n",
    "test_mytensor, test_labels = fill_tensors_and_labels(test_df, test_mytensor, test_labels, test_all_videos, test_maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "test_tensor_x = torch.tensor(test_mytensor, dtype=torch.float32).permute(0, 2, 1) \n",
    "test_tensor_y = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "# dataloader for test data\n",
    "test_dataset = TensorDataset(test_tensor_x, test_tensor_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "                              \n",
    "# predictions\n",
    "make_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0a6cb",
   "metadata": {},
   "source": [
    "### Parkinson Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d103cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f48f4fca",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9963fd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05b1cb21",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2ed1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44f934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79bf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c85856c1",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4180a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d297db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a05a8264",
   "metadata": {},
   "source": [
    "# modelo mejorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93ad434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin Espinoza\\anaconda3\\envs\\gpu3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6940, Validation Loss: 0.6943\n",
      "Epoch [2/200], Loss: 0.6919, Validation Loss: 0.6943\n",
      "Epoch [3/200], Loss: 0.6937, Validation Loss: 0.6941\n",
      "Epoch [4/200], Loss: 0.6942, Validation Loss: 0.6939\n",
      "Epoch [5/200], Loss: 0.6939, Validation Loss: 0.6938\n",
      "Epoch [6/200], Loss: 0.6941, Validation Loss: 0.6938\n",
      "Epoch [7/200], Loss: 0.6925, Validation Loss: 0.6937\n",
      "Epoch [8/200], Loss: 0.6928, Validation Loss: 0.6937\n",
      "Epoch [9/200], Loss: 0.6927, Validation Loss: 0.6938\n",
      "Epoch [10/200], Loss: 0.6928, Validation Loss: 0.6938\n",
      "Epoch [11/200], Loss: 0.6922, Validation Loss: 0.6937\n",
      "Epoch [12/200], Loss: 0.6925, Validation Loss: 0.6937\n",
      "Epoch [13/200], Loss: 0.6925, Validation Loss: 0.6936\n",
      "Epoch [14/200], Loss: 0.6934, Validation Loss: 0.6936\n",
      "Epoch [15/200], Loss: 0.6933, Validation Loss: 0.6936\n",
      "Epoch [16/200], Loss: 0.6918, Validation Loss: 0.6936\n",
      "Epoch [17/200], Loss: 0.6908, Validation Loss: 0.6935\n",
      "Epoch [18/200], Loss: 0.6923, Validation Loss: 0.6936\n",
      "Epoch [19/200], Loss: 0.6926, Validation Loss: 0.6935\n",
      "Epoch [20/200], Loss: 0.6922, Validation Loss: 0.6934\n",
      "Epoch [21/200], Loss: 0.6910, Validation Loss: 0.6933\n",
      "Epoch [22/200], Loss: 0.6922, Validation Loss: 0.6931\n",
      "Epoch [23/200], Loss: 0.6917, Validation Loss: 0.6929\n",
      "Epoch [24/200], Loss: 0.6893, Validation Loss: 0.6927\n",
      "Epoch [25/200], Loss: 0.6921, Validation Loss: 0.6926\n",
      "Epoch [26/200], Loss: 0.6908, Validation Loss: 0.6925\n",
      "Epoch [27/200], Loss: 0.6905, Validation Loss: 0.6923\n",
      "Epoch [28/200], Loss: 0.6933, Validation Loss: 0.6922\n",
      "Epoch [29/200], Loss: 0.6938, Validation Loss: 0.6921\n",
      "Epoch [30/200], Loss: 0.6930, Validation Loss: 0.6919\n",
      "Epoch [31/200], Loss: 0.6903, Validation Loss: 0.6918\n",
      "Epoch [32/200], Loss: 0.6918, Validation Loss: 0.6917\n",
      "Epoch [33/200], Loss: 0.6907, Validation Loss: 0.6916\n",
      "Epoch [34/200], Loss: 0.6900, Validation Loss: 0.6914\n",
      "Epoch [35/200], Loss: 0.6901, Validation Loss: 0.6912\n",
      "Epoch [36/200], Loss: 0.6915, Validation Loss: 0.6908\n",
      "Epoch [37/200], Loss: 0.6885, Validation Loss: 0.6904\n",
      "Epoch [38/200], Loss: 0.6925, Validation Loss: 0.6900\n",
      "Epoch [39/200], Loss: 0.6916, Validation Loss: 0.6893\n",
      "Epoch [40/200], Loss: 0.6886, Validation Loss: 0.6887\n",
      "Epoch [41/200], Loss: 0.6917, Validation Loss: 0.6880\n",
      "Epoch [42/200], Loss: 0.6903, Validation Loss: 0.6871\n",
      "Epoch [43/200], Loss: 0.6879, Validation Loss: 0.6860\n",
      "Epoch [44/200], Loss: 0.6903, Validation Loss: 0.6848\n",
      "Epoch [45/200], Loss: 0.6883, Validation Loss: 0.6832\n",
      "Epoch [46/200], Loss: 0.6862, Validation Loss: 0.6812\n",
      "Epoch [47/200], Loss: 0.6861, Validation Loss: 0.6790\n",
      "Epoch [48/200], Loss: 0.6856, Validation Loss: 0.6764\n",
      "Epoch [49/200], Loss: 0.6815, Validation Loss: 0.6726\n",
      "Epoch [50/200], Loss: 0.6803, Validation Loss: 0.6676\n",
      "Epoch [51/200], Loss: 0.6770, Validation Loss: 0.6606\n",
      "Epoch [52/200], Loss: 0.6731, Validation Loss: 0.6510\n",
      "Epoch [53/200], Loss: 0.6653, Validation Loss: 0.6353\n",
      "Epoch [54/200], Loss: 0.6525, Validation Loss: 0.6084\n",
      "Epoch [55/200], Loss: 0.6387, Validation Loss: 0.5641\n",
      "Epoch [56/200], Loss: 0.6184, Validation Loss: 0.5027\n",
      "Epoch [57/200], Loss: 0.6127, Validation Loss: 0.4710\n",
      "Epoch [58/200], Loss: 0.5885, Validation Loss: 0.4631\n",
      "Epoch [59/200], Loss: 0.6257, Validation Loss: 0.4373\n",
      "Epoch [60/200], Loss: 0.6171, Validation Loss: 0.4471\n",
      "Epoch [61/200], Loss: 0.5926, Validation Loss: 0.4770\n",
      "Epoch [62/200], Loss: 0.6260, Validation Loss: 0.4934\n",
      "Epoch [63/200], Loss: 0.6030, Validation Loss: 0.4852\n",
      "Epoch [64/200], Loss: 0.5757, Validation Loss: 0.4838\n",
      "Epoch [65/200], Loss: 0.6110, Validation Loss: 0.4973\n",
      "Epoch [66/200], Loss: 0.6203, Validation Loss: 0.4874\n",
      "Epoch [67/200], Loss: 0.6119, Validation Loss: 0.4916\n",
      "Epoch [68/200], Loss: 0.6280, Validation Loss: 0.4975\n",
      "Epoch [69/200], Loss: 0.5977, Validation Loss: 0.5025\n",
      "Epoch [70/200], Loss: 0.6060, Validation Loss: 0.4942\n",
      "Epoch [71/200], Loss: 0.5980, Validation Loss: 0.4782\n",
      "Epoch [72/200], Loss: 0.5981, Validation Loss: 0.4616\n",
      "Epoch [73/200], Loss: 0.5985, Validation Loss: 0.4502\n",
      "Epoch [74/200], Loss: 0.6075, Validation Loss: 0.4449\n",
      "Epoch [75/200], Loss: 0.5762, Validation Loss: 0.4418\n",
      "Epoch [76/200], Loss: 0.5745, Validation Loss: 0.4425\n",
      "Epoch [77/200], Loss: 0.5994, Validation Loss: 0.4415\n",
      "Epoch [78/200], Loss: 0.5806, Validation Loss: 0.4419\n",
      "Epoch [79/200], Loss: 0.5792, Validation Loss: 0.4269\n",
      "Epoch [80/200], Loss: 0.5709, Validation Loss: 0.4191\n",
      "Epoch [81/200], Loss: 0.5795, Validation Loss: 0.4169\n",
      "Epoch [82/200], Loss: 0.5859, Validation Loss: 0.4227\n",
      "Epoch [83/200], Loss: 0.5580, Validation Loss: 0.4318\n",
      "Epoch [84/200], Loss: 0.6141, Validation Loss: 0.4250\n",
      "Epoch [85/200], Loss: 0.5870, Validation Loss: 0.4138\n",
      "Epoch [86/200], Loss: 0.5701, Validation Loss: 0.4151\n",
      "Epoch [87/200], Loss: 0.5684, Validation Loss: 0.4198\n",
      "Epoch [88/200], Loss: 0.5883, Validation Loss: 0.4289\n",
      "Epoch [89/200], Loss: 0.5949, Validation Loss: 0.4389\n",
      "Epoch [90/200], Loss: 0.5859, Validation Loss: 0.4430\n",
      "Epoch [91/200], Loss: 0.5766, Validation Loss: 0.4265\n",
      "Epoch [92/200], Loss: 0.5833, Validation Loss: 0.4149\n",
      "Epoch [93/200], Loss: 0.5838, Validation Loss: 0.4185\n",
      "Epoch [94/200], Loss: 0.6041, Validation Loss: 0.4200\n",
      "Epoch [95/200], Loss: 0.5586, Validation Loss: 0.4371\n",
      "Epoch [96/200], Loss: 0.5842, Validation Loss: 0.4521\n",
      "Epoch [97/200], Loss: 0.5646, Validation Loss: 0.4545\n",
      "Epoch [98/200], Loss: 0.5733, Validation Loss: 0.4409\n",
      "Epoch [99/200], Loss: 0.5951, Validation Loss: 0.4253\n",
      "Epoch [100/200], Loss: 0.5892, Validation Loss: 0.4166\n",
      "Epoch [101/200], Loss: 0.5667, Validation Loss: 0.4143\n",
      "Epoch [102/200], Loss: 0.5807, Validation Loss: 0.4105\n",
      "Epoch [103/200], Loss: 0.5796, Validation Loss: 0.4095\n",
      "Epoch [104/200], Loss: 0.5567, Validation Loss: 0.4064\n",
      "Epoch [105/200], Loss: 0.5879, Validation Loss: 0.4016\n",
      "Epoch [106/200], Loss: 0.5765, Validation Loss: 0.4045\n",
      "Epoch [107/200], Loss: 0.5985, Validation Loss: 0.4082\n",
      "Epoch [108/200], Loss: 0.5531, Validation Loss: 0.4109\n",
      "Epoch [109/200], Loss: 0.5606, Validation Loss: 0.4058\n",
      "Epoch [110/200], Loss: 0.5591, Validation Loss: 0.4018\n",
      "Epoch [111/200], Loss: 0.5705, Validation Loss: 0.3978\n",
      "Epoch [112/200], Loss: 0.5658, Validation Loss: 0.3973\n",
      "Epoch [113/200], Loss: 0.5639, Validation Loss: 0.4008\n",
      "Epoch [114/200], Loss: 0.5884, Validation Loss: 0.4000\n",
      "Epoch [115/200], Loss: 0.5817, Validation Loss: 0.3961\n",
      "Epoch [116/200], Loss: 0.5524, Validation Loss: 0.3882\n",
      "Epoch [117/200], Loss: 0.5414, Validation Loss: 0.3861\n",
      "Epoch [118/200], Loss: 0.5728, Validation Loss: 0.3857\n",
      "Epoch [119/200], Loss: 0.5482, Validation Loss: 0.3930\n",
      "Epoch [120/200], Loss: 0.5837, Validation Loss: 0.4055\n",
      "Epoch [121/200], Loss: 0.5535, Validation Loss: 0.4074\n",
      "Epoch [122/200], Loss: 0.5669, Validation Loss: 0.4029\n",
      "Epoch [123/200], Loss: 0.5395, Validation Loss: 0.3969\n",
      "Epoch [124/200], Loss: 0.5347, Validation Loss: 0.3876\n",
      "Epoch [125/200], Loss: 0.5644, Validation Loss: 0.3789\n",
      "Epoch [126/200], Loss: 0.5581, Validation Loss: 0.3795\n",
      "Epoch [127/200], Loss: 0.5861, Validation Loss: 0.3814\n",
      "Epoch [128/200], Loss: 0.5705, Validation Loss: 0.3797\n",
      "Epoch [129/200], Loss: 0.5609, Validation Loss: 0.3819\n",
      "Epoch [130/200], Loss: 0.5445, Validation Loss: 0.3766\n",
      "Epoch [131/200], Loss: 0.5526, Validation Loss: 0.3745\n",
      "Epoch [132/200], Loss: 0.5602, Validation Loss: 0.3812\n",
      "Epoch [133/200], Loss: 0.5521, Validation Loss: 0.3875\n",
      "Epoch [134/200], Loss: 0.5352, Validation Loss: 0.3882\n",
      "Epoch [135/200], Loss: 0.5360, Validation Loss: 0.3785\n",
      "Epoch [136/200], Loss: 0.5515, Validation Loss: 0.3658\n",
      "Epoch [137/200], Loss: 0.5529, Validation Loss: 0.3551\n",
      "Epoch [138/200], Loss: 0.5378, Validation Loss: 0.3535\n",
      "Epoch [139/200], Loss: 0.5716, Validation Loss: 0.3590\n",
      "Epoch [140/200], Loss: 0.5551, Validation Loss: 0.3728\n",
      "Epoch [141/200], Loss: 0.5331, Validation Loss: 0.3780\n",
      "Epoch [142/200], Loss: 0.5154, Validation Loss: 0.3682\n",
      "Epoch [143/200], Loss: 0.5397, Validation Loss: 0.3543\n",
      "Epoch [144/200], Loss: 0.5357, Validation Loss: 0.3486\n",
      "Epoch [145/200], Loss: 0.5265, Validation Loss: 0.3481\n",
      "Epoch [146/200], Loss: 0.5355, Validation Loss: 0.3575\n",
      "Epoch [147/200], Loss: 0.5312, Validation Loss: 0.3753\n",
      "Epoch [148/200], Loss: 0.5661, Validation Loss: 0.3718\n",
      "Epoch [149/200], Loss: 0.5306, Validation Loss: 0.3614\n",
      "Epoch [150/200], Loss: 0.5183, Validation Loss: 0.3321\n",
      "Epoch [151/200], Loss: 0.5491, Validation Loss: 0.3293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/200], Loss: 0.5414, Validation Loss: 0.3529\n",
      "Epoch [153/200], Loss: 0.5058, Validation Loss: 0.3704\n",
      "Epoch [154/200], Loss: 0.5042, Validation Loss: 0.3728\n",
      "Epoch [155/200], Loss: 0.5182, Validation Loss: 0.3685\n",
      "Epoch [156/200], Loss: 0.5182, Validation Loss: 0.3361\n",
      "Epoch [157/200], Loss: 0.5129, Validation Loss: 0.3256\n",
      "Epoch [158/200], Loss: 0.6259, Validation Loss: 0.3242\n",
      "Epoch [159/200], Loss: 0.4894, Validation Loss: 0.3674\n",
      "Epoch [160/200], Loss: 0.5637, Validation Loss: 0.4358\n",
      "Epoch [161/200], Loss: 0.5624, Validation Loss: 0.4456\n",
      "Epoch [162/200], Loss: 0.5915, Validation Loss: 0.4023\n",
      "Epoch [163/200], Loss: 0.5598, Validation Loss: 0.3716\n",
      "Epoch [164/200], Loss: 0.5550, Validation Loss: 0.3474\n",
      "Epoch [165/200], Loss: 0.5265, Validation Loss: 0.3431\n",
      "Epoch [166/200], Loss: 0.5087, Validation Loss: 0.3440\n",
      "Epoch [167/200], Loss: 0.5413, Validation Loss: 0.3420\n",
      "Epoch [168/200], Loss: 0.5074, Validation Loss: 0.3468\n",
      "Epoch [169/200], Loss: 0.5224, Validation Loss: 0.3567\n",
      "Epoch [170/200], Loss: 0.5395, Validation Loss: 0.3590\n",
      "Epoch [171/200], Loss: 0.5171, Validation Loss: 0.3537\n",
      "Epoch [172/200], Loss: 0.5252, Validation Loss: 0.3396\n",
      "Epoch [173/200], Loss: 0.5299, Validation Loss: 0.3209\n",
      "Epoch [174/200], Loss: 0.5207, Validation Loss: 0.3140\n",
      "Epoch [175/200], Loss: 0.4828, Validation Loss: 0.3138\n",
      "Epoch [176/200], Loss: 0.5190, Validation Loss: 0.3099\n",
      "Epoch [177/200], Loss: 0.5367, Validation Loss: 0.3054\n",
      "Epoch [178/200], Loss: 0.5146, Validation Loss: 0.3092\n",
      "Epoch [179/200], Loss: 0.5353, Validation Loss: 0.3288\n",
      "Epoch [180/200], Loss: 0.5156, Validation Loss: 0.3314\n",
      "Epoch [181/200], Loss: 0.5212, Validation Loss: 0.3246\n",
      "Epoch [182/200], Loss: 0.5052, Validation Loss: 0.3155\n",
      "Epoch [183/200], Loss: 0.5017, Validation Loss: 0.3172\n",
      "Epoch [184/200], Loss: 0.5081, Validation Loss: 0.3180\n",
      "Epoch [185/200], Loss: 0.5074, Validation Loss: 0.3167\n",
      "Epoch [186/200], Loss: 0.5362, Validation Loss: 0.3171\n",
      "Epoch [187/200], Loss: 0.4951, Validation Loss: 0.3346\n",
      "Epoch [188/200], Loss: 0.4970, Validation Loss: 0.3463\n",
      "Epoch [189/200], Loss: 0.5192, Validation Loss: 0.3339\n",
      "Epoch [190/200], Loss: 0.4878, Validation Loss: 0.3075\n",
      "Epoch [191/200], Loss: 0.4841, Validation Loss: 0.2996\n",
      "Epoch [192/200], Loss: 0.5578, Validation Loss: 0.2930\n",
      "Epoch [193/200], Loss: 0.4968, Validation Loss: 0.3113\n",
      "Epoch [194/200], Loss: 0.4899, Validation Loss: 0.3300\n",
      "Epoch [195/200], Loss: 0.5230, Validation Loss: 0.3290\n",
      "Epoch [196/200], Loss: 0.5118, Validation Loss: 0.3089\n",
      "Epoch [197/200], Loss: 0.4988, Validation Loss: 0.2958\n",
      "Epoch [198/200], Loss: 0.5155, Validation Loss: 0.2988\n",
      "Epoch [199/200], Loss: 0.4873, Validation Loss: 0.2958\n",
      "Epoch [200/200], Loss: 0.5270, Validation Loss: 0.2827\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7778\n",
      "Test Recall: 1.0000\n",
      "Test F1-score: 0.8333\n",
      "Test AUROC: 0.7500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the file\n",
    "environment_path = \"C:\\\\MARTIN EDUARDO\\\\University Of Leeds\\\\Dissertation\\\\Classification_bradykinesia_KalmanFilter\"\n",
    "file_path = environment_path + \"\\\\mediaPipe_videos.csv\"\n",
    "\n",
    "# Define ParkinsonRNN model\n",
    "class ParkinsonRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(ParkinsonRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# read the file\n",
    "def read_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# read videos\n",
    "def read_videos(file_path):\n",
    "    student_names = [name for name in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, name))]\n",
    "    all_videos = []\n",
    "    for student_name in student_names:\n",
    "        video_path = os.path.join(file_path, student_name)\n",
    "        video_names = [os.path.splitext(name)[0] for name in os.listdir(video_path) if os.path.isfile(os.path.join(video_path, name))]\n",
    "        all_videos.extend(video_names)\n",
    "    return all_videos\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "def calculate_maxT(df, all_videos):\n",
    "    maxT = 0\n",
    "    for video in all_videos:\n",
    "        maxT = max(maxT, df[df['image_name'].str.startswith(video)].shape[0])\n",
    "    return maxT\n",
    "\n",
    "# fill the tensor and labels\n",
    "def fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT):\n",
    "    num_videos = len(all_videos)\n",
    "    for i, video in enumerate(all_videos):\n",
    "        video_data = df[df['image_name'].str.startswith(video)]\n",
    "        T = video_data.shape[0]\n",
    "        if T <= maxT:\n",
    "            mytensor[i, 0, :T] = video_data['finger_x']\n",
    "            mytensor[i, 1, :T] = video_data['finger_y']\n",
    "            mytensor[i, 2, :T] = video_data['thumb_x']\n",
    "            mytensor[i, 3, :T] = video_data['thumb_y']\n",
    "        else:\n",
    "            mytensor[i, 0, :maxT] = video_data['finger_x'][:maxT]\n",
    "            mytensor[i, 1, :maxT] = video_data['finger_y'][:maxT]\n",
    "            mytensor[i, 2, :maxT] = video_data['thumb_x'][:maxT]\n",
    "            mytensor[i, 3, :maxT] = video_data['thumb_y'][:maxT]\n",
    "        if video.startswith('P'):\n",
    "            labels[i] = 1\n",
    "    return mytensor, labels\n",
    "\n",
    "# dataloaders for training\n",
    "def create_train_and_validation_loaders(tensor_x, tensor_y, batch_size):\n",
    "    # split into training and validation\n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    validation_split = 0.2\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    validation_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "# train the Parkinson model\n",
    "def training_model(model, train_loader, validation_loader, num_epochs, learning_rate):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # to store the losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, labels in train_loader:\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in validation_loader:\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(validation_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# make the predictions\n",
    "def make_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            outputs = model(sequences)\n",
    "            predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "            test_predictions.extend(predictions)\n",
    "            test_targets.extend(labels.numpy())\n",
    "\n",
    "    # metrics\n",
    "    test_predictions = np.array(test_predictions).flatten()\n",
    "    test_targets = np.array(test_targets)\n",
    "\n",
    "    accuracy = accuracy_score(test_targets, np.round(test_predictions))\n",
    "    recall = recall_score(test_targets, np.round(test_predictions))\n",
    "    f1 = f1_score(test_targets, np.round(test_predictions))\n",
    "    roc_auc = roc_auc_score(test_targets, test_predictions)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1-score: {f1:.4f}')\n",
    "    print(f'Test AUROC: {roc_auc:.4f}')\n",
    "\n",
    "# ploting the losses\n",
    "def plot_losses(train_losses, val_losses, num_epochs):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# models parameters\n",
    "batch_size = 32\n",
    "input_size = 4\n",
    "hidden_size = 256  # Increased hidden size\n",
    "num_layers = 3  # Increased number of layers\n",
    "output_size = 1\n",
    "learning_rate = 0.0001\n",
    "dropout = 0.5\n",
    "num_epochs = 200\n",
    "\n",
    "# read the files\n",
    "df = read_file(file_path) # train file\n",
    "\n",
    "# read videos\n",
    "all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\videos_lowfps\\\\\")\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "maxT = calculate_maxT(df, all_videos)\n",
    "\n",
    "# create the tensor and labels\n",
    "num_videos = len(all_videos)\n",
    "mytensor = np.zeros([num_videos, 4, maxT])\n",
    "labels = np.zeros(num_videos)\n",
    "\n",
    "# fill the tensor and labels\n",
    "mytensor, labels = fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "tensor_x = torch.tensor(mytensor, dtype=torch.float32).permute(0, 2, 1)\n",
    "tensor_y = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# train and validation loaders\n",
    "train_loader, validation_loader = create_train_and_validation_loaders(tensor_x, tensor_y, batch_size)\n",
    "\n",
    "# train the model\n",
    "model = ParkinsonRNN(input_size, hidden_size, num_layers, output_size, dropout)\n",
    "model, train_losses, val_losses = training_model(model, train_loader, validation_loader, num_epochs, learning_rate)\n",
    "\n",
    "plot_losses(train_losses, val_losses, num_epochs)\n",
    "\n",
    "# read the test file\n",
    "test_df = read_file(environment_path + \"\\\\test_mediaPipe_videos.csv\")\n",
    "\n",
    "# read the test videos\n",
    "test_all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\test_videos_lowfps\\\\\")\n",
    "\n",
    "# calculate the number of max frames (T) for test data\n",
    "test_maxT = calculate_maxT(test_df, test_all_videos)\n",
    "\n",
    "# create the tensor and labels for test data\n",
    "test_num_videos = len(test_all_videos)\n",
    "test_mytensor = np.zeros([test_num_videos, 4, test_maxT])\n",
    "test_labels = np.zeros(test_num_videos)\n",
    "\n",
    "# fill the tensor and labels for test data\n",
    "test_mytensor, test_labels = fill_tensors_and_labels(test_df, test_mytensor, test_labels, test_all_videos, test_maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "test_tensor_x = torch.tensor(test_mytensor, dtype=torch.float32).permute(0, 2, 1)\n",
    "test_tensor_y = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "# dataloader for test data\n",
    "test_dataset = TensorDataset(test_tensor_x, test_tensor_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# make predictions\n",
    "make_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003dd4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa4e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce77aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aea7200d",
   "metadata": {},
   "source": [
    "# modelo mejorado con distance column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d71107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the file\n",
    "environment_path = \"C:\\\\MARTIN EDUARDO\\\\University Of Leeds\\\\Dissertation\\\\Classification_bradykinesia_KalmanFilter\"\n",
    "file_path = environment_path + \"\\\\Data\\\\data\\\\mediaPipe_videos.csv\"\n",
    "\n",
    "# Define ParkinsonRNN model\n",
    "class ParkinsonRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(ParkinsonRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# read the file\n",
    "def read_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# read videos\n",
    "def read_videos(file_path):\n",
    "    student_names = [name for name in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, name))]\n",
    "    all_videos = []\n",
    "    for student_name in student_names:\n",
    "        video_path = os.path.join(file_path, student_name)\n",
    "        video_names = [os.path.splitext(name)[0] for name in os.listdir(video_path) if os.path.isfile(os.path.join(video_path, name))]\n",
    "        all_videos.extend(video_names)\n",
    "    return all_videos\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "def calculate_maxT(df, all_videos):\n",
    "    maxT = 0\n",
    "    for video in all_videos:\n",
    "        maxT = max(maxT, df[df['image_name'].str.startswith(video)].shape[0])\n",
    "    return maxT\n",
    "\n",
    "# fill the tensor and labels\n",
    "def fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT):\n",
    "    num_videos = len(all_videos)\n",
    "    for i, video in enumerate(all_videos):\n",
    "        video_data = df[df['image_name'].str.startswith(video)]\n",
    "        T = video_data.shape[0]\n",
    "        if T <= maxT:\n",
    "            mytensor[i, 0, :T] = video_data['finger_x']\n",
    "            mytensor[i, 1, :T] = video_data['finger_y']\n",
    "            mytensor[i, 2, :T] = video_data['thumb_x']\n",
    "            mytensor[i, 3, :T] = video_data['thumb_y']\n",
    "            mytensor[i, 4, :T] = video_data['distance']\n",
    "        else:\n",
    "            mytensor[i, 0, :maxT] = video_data['finger_x'][:maxT]\n",
    "            mytensor[i, 1, :maxT] = video_data['finger_y'][:maxT]\n",
    "            mytensor[i, 2, :maxT] = video_data['thumb_x'][:maxT]\n",
    "            mytensor[i, 3, :maxT] = video_data['thumb_y'][:maxT]\n",
    "            mytensor[i, 4, :maxT] = video_data['distance'][:maxT]\n",
    "        if video.startswith('P'):\n",
    "            labels[i] = 1\n",
    "    return mytensor, labels\n",
    "\n",
    "# dataloaders for training\n",
    "def create_train_and_validation_loaders(tensor_x, tensor_y, batch_size):\n",
    "    # split into training and validation\n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    validation_split = 0.2\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    validation_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "# train the Parkinson model\n",
    "def training_model(model, train_loader, validation_loader, num_epochs, learning_rate):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # to store the losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, labels in train_loader:\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in validation_loader:\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(validation_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# make the predictions\n",
    "def make_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            outputs = model(sequences)\n",
    "            predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "            test_predictions.extend(predictions)\n",
    "            test_targets.extend(labels.numpy())\n",
    "\n",
    "    # metrics\n",
    "    test_predictions = np.array(test_predictions).flatten()\n",
    "    test_targets = np.array(test_targets)\n",
    "\n",
    "    accuracy = accuracy_score(test_targets, np.round(test_predictions))\n",
    "    recall = recall_score(test_targets, np.round(test_predictions))\n",
    "    f1 = f1_score(test_targets, np.round(test_predictions))\n",
    "    roc_auc = roc_auc_score(test_targets, test_predictions)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1-score: {f1:.4f}')\n",
    "    print(f'Test AUROC: {roc_auc:.4f}')\n",
    "\n",
    "# ploting the losses\n",
    "def plot_losses(train_losses, val_losses, num_epochs):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# models parameters\n",
    "batch_size = 32\n",
    "input_size = 5  # Actualizamos el input_size a 5 para incluir la nueva caracterstica\n",
    "hidden_size = 256  # Increased hidden size\n",
    "num_layers = 3  # Increased number of layers\n",
    "output_size = 1\n",
    "learning_rate = 0.0001\n",
    "dropout = 0.5\n",
    "num_epochs = 200\n",
    "\n",
    "# read the files\n",
    "df = read_file(file_path) # train file\n",
    "\n",
    "# read videos\n",
    "all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\videos_lowfps\\\\\")\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "maxT = calculate_maxT(df, all_videos)\n",
    "\n",
    "# create the tensor and labels\n",
    "num_videos = len(all_videos)\n",
    "mytensor = np.zeros([num_videos, 5, maxT])  # Incrementamos el tamao a 5 para incluir la nueva caracterstica\n",
    "labels = np.zeros(num_videos)\n",
    "\n",
    "# fill the tensor and labels\n",
    "mytensor, labels = fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "tensor_x = torch.tensor(mytensor, dtype=torch.float32).permute(0, 2, 1)\n",
    "tensor_y = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# train and validation loaders\n",
    "train_loader, validation_loader = create_train_and_validation_loaders(tensor_x, tensor_y, batch_size)\n",
    "\n",
    "# train the model\n",
    "model = ParkinsonRNN(input_size, hidden_size, num_layers, output_size, dropout)\n",
    "model, train_losses, val_losses = training_model(model, train_loader, validation_loader, num_epochs, learning_rate)\n",
    "\n",
    "plot_losses(train_losses, val_losses, num_epochs)\n",
    "\n",
    "# read the test file\n",
    "test_df = read_file(environment_path + \"\\\\Data\\\\data\\\\test_mediaPipe_videos.csv\")\n",
    "\n",
    "# read the test videos\n",
    "test_all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\test_videos_lowfps\\\\\")\n",
    "\n",
    "# calculate the number of max frames (T) for test data\n",
    "test_maxT = calculate_maxT(test_df, test_all_videos)\n",
    "\n",
    "# create the tensor and labels for test data\n",
    "test_num_videos = len(test_all_videos)\n",
    "test_mytensor = np.zeros([test_num_videos, 5, test_maxT])  # Incrementamos el tamao a 5 para incluir la nueva caracterstica\n",
    "test_labels = np.zeros(test_num_videos)\n",
    "\n",
    "# fill the tensor and labels for test data\n",
    "test_mytensor, test_labels = fill_tensors_and_labels(test_df, test_mytensor, test_labels, test_all_videos, test_maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "test_tensor_x = torch.tensor(test_mytensor, dtype=torch.float32).permute(0, 2, 1)\n",
    "test_tensor_y = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "# dataloader for test data\n",
    "test_dataset = TensorDataset(test_tensor_x, test_tensor_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# make predictions\n",
    "make_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfba78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6bdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1d821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c0c6857",
   "metadata": {},
   "source": [
    "# modelo original con distance column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c97e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the file\n",
    "environment_path = \"C:\\\\MARTIN EDUARDO\\\\University Of Leeds\\\\Dissertation\\\\Classification_bradykinesia_KalmanFilter\"\n",
    "file_path = environment_path + \"\\\\Data\\\\data\\\\mediaPipe_videos.csv\"\n",
    "\n",
    "class ParkinsonRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(ParkinsonRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device) \n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# read the file\n",
    "def read_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# read videos\n",
    "def read_videos(file_path):\n",
    "    student_names = [name for name in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, name))]\n",
    "    all_videos = []\n",
    "    for student_name in student_names:\n",
    "        video_path = os.path.join(file_path, student_name)\n",
    "        video_names = [os.path.splitext(name)[0] for name in os.listdir(video_path) if os.path.isfile(os.path.join(video_path, name))]\n",
    "        all_videos.extend(video_names)\n",
    "    return all_videos\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "def calculate_maxT(df, all_videos):\n",
    "    maxT = 0\n",
    "    for video in all_videos:\n",
    "        maxT = max(maxT, df[df['image_name'].str.startswith(video)].shape[0])\n",
    "    return maxT\n",
    "\n",
    "# fill the tensor and labels\n",
    "def fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT):\n",
    "    num_videos = len(all_videos)\n",
    "    for i, video in enumerate(all_videos):\n",
    "        video_data = df[df['image_name'].str.startswith(video)]\n",
    "        T = video_data.shape[0]\n",
    "        if T <= maxT:\n",
    "            mytensor[i, 0, :T] = video_data['finger_x']\n",
    "            mytensor[i, 1, :T] = video_data['finger_y']\n",
    "            mytensor[i, 2, :T] = video_data['thumb_x']\n",
    "            mytensor[i, 3, :T] = video_data['thumb_y']\n",
    "            mytensor[i, 4, :T] = video_data['distance']\n",
    "        else:\n",
    "            mytensor[i, 0, :maxT] = video_data['finger_x'][:maxT]\n",
    "            mytensor[i, 1, :maxT] = video_data['finger_y'][:maxT]\n",
    "            mytensor[i, 2, :maxT] = video_data['thumb_x'][:maxT]\n",
    "            mytensor[i, 3, :maxT] = video_data['thumb_y'][:maxT]\n",
    "            mytensor[i, 4, :maxT] = video_data['distance'][:maxT]\n",
    "        if video.startswith('P'):\n",
    "            labels[i] = 1\n",
    "    return mytensor, labels\n",
    "\n",
    "# dataloaders for training\n",
    "def create_train_and_validation_loaders(tensor_x, tensor_y, batch_size):\n",
    "    # split into training and validation\n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    validation_split = 0.2\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    validation_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "# train the Parkinson model\n",
    "def training_model(model, train_loader, validation_loader, labels, num_epochs, learning_rate):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # to store the losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for sequences, labels in train_loader:\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in validation_loader:\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(validation_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# make the predictions\n",
    "def make_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            outputs = model(sequences)\n",
    "            predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "            test_predictions.extend(predictions)\n",
    "            test_targets.extend(labels.numpy())\n",
    "\n",
    "    # metrics\n",
    "    test_predictions = np.array(test_predictions).flatten()\n",
    "    test_targets = np.array(test_targets)\n",
    "\n",
    "    accuracy = accuracy_score(test_targets, np.round(test_predictions))\n",
    "    recall = recall_score(test_targets, np.round(test_predictions))\n",
    "    f1 = f1_score(test_targets, np.round(test_predictions))\n",
    "    roc_auc = roc_auc_score(test_targets, test_predictions)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1-score: {f1:.4f}')\n",
    "    print(f'Test AUROC: {roc_auc:.4f}')\n",
    "    \n",
    "# ploting the losses\n",
    "def plot_losses(train_losses, val_losses, num_epochs):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# models parameters\n",
    "batch_size = 32\n",
    "input_size = 5  # Actualizamos el input_size a 5 para incluir la nueva caracterstica\n",
    "hidden_size = 256  \n",
    "num_layers = 3\n",
    "output_size = 1\n",
    "learning_rate = 0.0001 \n",
    "dropout = 0.5 \n",
    "num_epochs = 200\n",
    "\n",
    "# read the files\n",
    "df = pd.read_csv(file_path)  # train file\n",
    "\n",
    "# read videos\n",
    "all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\videos_lowfps\\\\\")\n",
    "\n",
    "# calculate the number of max frames (T)\n",
    "maxT = calculate_maxT(df, all_videos)\n",
    "\n",
    "# create the tensor and labels\n",
    "num_videos = len(all_videos)\n",
    "mytensor = np.zeros([num_videos, 5, maxT])  # Incrementamos el tamao a 5 para incluir la nueva caracterstica\n",
    "labels = np.zeros(num_videos)\n",
    "\n",
    "# fill the tensor and labels\n",
    "fill_tensors_and_labels(df, mytensor, labels, all_videos, maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "tensor_x = torch.tensor(mytensor, dtype=torch.float32).permute(0, 2, 1) \n",
    "tensor_y = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# train and validation loaders\n",
    "train_loader, validation_loader = create_train_and_validation_loaders(tensor_x, tensor_y, batch_size)\n",
    "\n",
    "# train the model\n",
    "model = ParkinsonRNN(input_size, hidden_size, num_layers, output_size, dropout)\n",
    "model, train_losses, val_losses = training_model(model, train_loader, validation_loader, labels, num_epochs, learning_rate)\n",
    "\n",
    "plot_losses(train_losses, val_losses, num_epochs)\n",
    "\n",
    "# read the file (dataframe)\n",
    "test_df = read_file(environment_path + \"\\\\Data\\\\data\\\\test_mediaPipe_videos.csv\")\n",
    "\n",
    "# read the videos (list)\n",
    "test_all_videos = read_videos(environment_path + \"\\\\Data\\\\videos_data\\\\test_videos_lowfps\\\\\")\n",
    "                              \n",
    "# calculate the number of max frames (T)\n",
    "test_maxT = calculate_maxT(test_df, test_all_videos)\n",
    "                              \n",
    "# create the tensor and labels\n",
    "test_num_videos = len(test_all_videos)\n",
    "test_mytensor = np.zeros([test_num_videos, 5, test_maxT])  # Incrementamos el tamao a 5 para incluir la nueva caracterstica\n",
    "test_labels = np.zeros(test_num_videos)\n",
    "                      \n",
    "# fill the tensor and labels\n",
    "test_mytensor, test_labels = fill_tensors_and_labels(test_df, test_mytensor, test_labels, test_all_videos, test_maxT)\n",
    "\n",
    "# tensors for x and y\n",
    "test_tensor_x = torch.tensor(test_mytensor, dtype=torch.float32).permute(0, 2, 1) \n",
    "test_tensor_y = torch.tensor(test_labels, dtype=torch.float32)\n",
    "\n",
    "# dataloader for test data\n",
    "test_dataset = TensorDataset(test_tensor_x, test_tensor_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "                              \n",
    "# predictions\n",
    "make_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9879fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
